{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x6W0t6kw13B9"
   },
   "outputs": [],
   "source": [
    "#Lab Glassware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2WS2wlR2BHX",
    "outputId": "5fb291f7-86d9-4da4-c0c6-c3b18ab9338d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\python312\\lib\\site-packages (1.2.11)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from roboflow) (2025.10.5)\n",
      "Requirement already satisfied: idna==3.7 in c:\\python312\\lib\\site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in c:\\python312\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from roboflow) (1.4.9)\n",
      "Requirement already satisfied: matplotlib in c:\\python312\\lib\\site-packages (from roboflow) (3.10.7)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\python312\\lib\\site-packages (from roboflow) (2.2.6)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in c:\\python312\\lib\\site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\python312\\lib\\site-packages (from roboflow) (12.0.0)\n",
      "Requirement already satisfied: pi-heif<2 in c:\\python312\\lib\\site-packages (from roboflow) (1.1.1)\n",
      "Requirement already satisfied: pillow-avif-plugin<2 in c:\\python312\\lib\\site-packages (from roboflow) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\python312\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in c:\\python312\\lib\\site-packages (from roboflow) (1.2.1)\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from roboflow) (2.32.5)\n",
      "Requirement already satisfied: six in c:\\python312\\lib\\site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\python312\\lib\\site-packages (from roboflow) (2.5.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\python312\\lib\\site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\python312\\lib\\site-packages (from roboflow) (6.0.3)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\python312\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in c:\\python312\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib->roboflow) (1.3.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib->roboflow) (4.60.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from matplotlib->roboflow) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\python312\\lib\\site-packages (from matplotlib->roboflow) (3.2.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->roboflow) (3.4.4)\n",
      "Requirement already satisfied: tensorflow in c:\\python312\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\python312\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\python312\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\python312\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\python312\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\python312\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\python312\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\python312\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\python312\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\python312\\lib\\site-packages (from tensorflow) (6.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python312\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\python312\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\python312\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\python312\\lib\\site-packages (from tensorflow) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\python312\\lib\\site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\python312\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\python312\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\python312\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\python312\\lib\\site-packages (from tensorflow) (2.2.6)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\python312\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\python312\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\python312\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\python312\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\python312\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python312\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\python312\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\python312\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python312\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python312\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\python312\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\python312\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\python312\\lib\\site-packages (from opencv-python) (2.2.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\python312\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\python312\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python312\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\python312\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\python312\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\python312\\lib\\site-packages (0.22.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\python312\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python312\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\python312\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\python312\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\python312\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Instala√ß√£o de bibliotecas essenciais\n",
    "!pip install roboflow\n",
    "!pip install tensorflow\n",
    "!pip install opencv-python\n",
    "!pip install matplotlib\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j6o6QWiR2OYh"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importa√ß√£o das bibliotecas\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Importa√ß√£o das bibliotecas\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from roboflow import Roboflow\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9u2gj0E2jPc",
    "outputId": "385467f5-84c0-4f62-a48d-ac596458a587"
   },
   "outputs": [],
   "source": [
    "# Conex√£o com dataset de vidrarias de laborat√≥rio via Roboflow\n",
    "rf = Roboflow(api_key=\"mpV6g84DqvN6HUqz9mt1\")\n",
    "project = rf.workspace(\"lab-identification\").project(\"lab-identification-y2nq4\")\n",
    "version = project.version(11)\n",
    "dataset = version.download(\"coco\")  # formato compat√≠vel com PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TP4rpyro230k"
   },
   "outputs": [],
   "source": [
    "# Hiperpar√¢metros para treinamento\n",
    "BATCH_SIZE = 2\n",
    "IMAGE_SIZE = 640  # conforme o pr√©-processamento do dataset\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4tUASCV_27cY",
    "outputId": "e760797e-798e-4b8b-e4f4-76c080d040c8"
   },
   "outputs": [],
   "source": [
    "# Bloco para sele√ß√£o de dispositivo (CUDA, MPS ou CPU)\n",
    "if torch.cuda.is_available():\n",
    "    # Prioridade 1: GPU NVIDIA (CUDA)\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Dispositivo selecionado: GPU NVIDIA (CUDA)\")\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Prioridade 2: GPU Apple (MPS)\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Dispositivo selecionado: GPU Apple (MPS)\")\n",
    "\n",
    "else:\n",
    "    # Fallback: CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Dispositivo selecionado: CPU\")\n",
    "\n",
    "print(f'Usando dispositivo: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Edz2k5we3DkP"
   },
   "outputs": [],
   "source": [
    "# Definir as transforma√ß√µes para os dados\n",
    "transformacoes = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converte para tensor e escala para [0, 1]\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406],  # M√©dia dos canais RGB\n",
    "                         #std=[0.229, 0.224, 0.225])   # Desvio padr√£o dos canais RGB\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9N1PyYT8zCb"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def preparar_anotacoes_coco(json_path):\n",
    "    with open(json_path) as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    # Mapear categorias para √≠ndices\n",
    "    categories = coco[\"categories\"]\n",
    "    class_to_idx = {cat[\"name\"]: cat[\"id\"] for cat in categories}\n",
    "\n",
    "    # Mapear ID da imagem para nome do arquivo\n",
    "    id_to_filename = {img[\"id\"]: img[\"file_name\"] for img in coco[\"images\"]}\n",
    "\n",
    "    # Agrupar anota√ß√µes por imagem\n",
    "    grouped = defaultdict(lambda: {\"boxes\": [], \"labels\": []})\n",
    "    for ann in coco[\"annotations\"]:\n",
    "        image_id = ann[\"image_id\"]\n",
    "        filename = id_to_filename[image_id]\n",
    "        x, y, w, h = ann[\"bbox\"]\n",
    "        box = [x, y, x + w, y + h]\n",
    "        label = ann[\"category_id\"]\n",
    "\n",
    "        grouped[filename][\"boxes\"].append(box)\n",
    "        grouped[filename][\"labels\"].append(label)\n",
    "\n",
    "    # Lista final de anota√ß√µes\n",
    "    annotations = [\n",
    "        {\n",
    "            \"filename\": fname,\n",
    "            \"boxes\": grouped[fname][\"boxes\"],\n",
    "            \"labels\": grouped[fname][\"labels\"]\n",
    "        }\n",
    "        for fname in grouped\n",
    "    ]\n",
    "\n",
    "    return annotations, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gyn_ftjY4G0W"
   },
   "outputs": [],
   "source": [
    "# Classe personalizada\n",
    "class LabGlasswareDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, annotations, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.annotations = annotations\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ann = self.annotations[idx]\n",
    "        img_path = os.path.join(self.image_dir, ann[\"filename\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        boxes = torch.tensor(ann[\"boxes\"], dtype=torch.float32)\n",
    "        labels = torch.tensor(ann[\"labels\"], dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFA4UWdG4qOA"
   },
   "outputs": [],
   "source": [
    "# Diret√≥rios\n",
    "base_dir = \"/content/LAB-IDENTIFICATION-11\"\n",
    "paths = {\n",
    "    \"train\": os.path.join(base_dir, \"train\"),\n",
    "    \"valid\": os.path.join(base_dir, \"valid\"),\n",
    "    \"test\": os.path.join(base_dir, \"test\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niBn8NB_4vv5"
   },
   "outputs": [],
   "source": [
    "# Anota√ß√µes\n",
    "annotations_train, class_to_idx = preparar_anotacoes_coco(os.path.join(paths[\"train\"], \"_annotations.coco.json\"))\n",
    "annotations_valid, _ = preparar_anotacoes_coco(os.path.join(paths[\"valid\"], \"_annotations.coco.json\"))\n",
    "annotations_test, _ = preparar_anotacoes_coco(os.path.join(paths[\"test\"], \"_annotations.coco.json\"))\n",
    "\n",
    "# Datasets\n",
    "dataset_treino = LabGlasswareDataset(paths[\"train\"], annotations_train, transformacoes)\n",
    "dataset_validacao = LabGlasswareDataset(paths[\"valid\"], annotations_valid, transformacoes)\n",
    "dataset_teste = LabGlasswareDataset(paths[\"test\"], annotations_test, transformacoes)\n",
    "\n",
    "dataloader_treino = DataLoader(dataset_treino, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "dataloader_validacao = DataLoader(dataset_validacao, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "dataloader_teste = DataLoader(dataset_teste, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8D7PStLl40_A"
   },
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "dataloader_treino = DataLoader(dataset_treino, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "dataloader_validacao = DataLoader(dataset_validacao, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "dataloader_teste = DataLoader(dataset_teste, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05l1tW90FPP8",
    "outputId": "c70092c3-d2eb-4c04-c0ed-00bebe6d3049"
   },
   "outputs": [],
   "source": [
    "# Criar o modelo com n√∫mero de classes personalizado\n",
    "\n",
    "# N√∫mero de classes (inclui fundo = 0)\n",
    "NUM_CLASSES = len(class_to_idx) + 1\n",
    "\n",
    "# Carregar modelo pr√©-treinado\n",
    "modelo = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# Substituir o cabe√ßote de classifica√ß√£o\n",
    "in_features = modelo.roi_heads.box_predictor.cls_score.in_features\n",
    "modelo.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASSES)\n",
    "\n",
    "# Enviar para o dispositivo\n",
    "modelo.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_6owoKZFfXM"
   },
   "outputs": [],
   "source": [
    "# Definir otimizador e fun√ß√£o de perda\n",
    "import torch.optim as optim\n",
    "\n",
    "params = [p for p in modelo.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=LEARNING_RATE, momentum=0.9, weight_decay=0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CG2BGMORFuDp",
    "outputId": "aca279d0-8352-42f2-c87e-f6ad920db0d8"
   },
   "outputs": [],
   "source": [
    "# Loop de treinamento\n",
    "\n",
    "modelo.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nüîÅ √âpoca {epoch+1}/{EPOCHS}\")\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    # === LOOP DE TREINAMENTO ===\n",
    "    for images, targets in tqdm(dataloader_treino, desc=f\"Treinando √©poca {epoch+1}\"):\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # C√°lculo da perda\n",
    "        loss_dict = modelo(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Acumular perda total\n",
    "        epoch_loss += losses.item()\n",
    "\n",
    "    # M√©dia da perda da √©poca\n",
    "    epoch_loss /= len(dataloader_treino)\n",
    "    print(f\"üìâ Loss m√©dio de treino na √©poca {epoch+1}: {epoch_loss:.4f}\")\n",
    "\n",
    "    # === LOOP DE VALIDA√á√ÉO ===\n",
    "    modelo.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(dataloader_validacao, desc=\"Validando\"):\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = modelo(images, targets)\n",
    "            if isinstance(loss_dict, dict):\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "                val_loss += losses.item()\n",
    "\n",
    "    val_loss /= len(dataloader_validacao)\n",
    "    print(f\"‚úÖ Loss m√©dio de valida√ß√£o: {val_loss:.4f}\")\n",
    "    modelo.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NYAG8tPGFqN"
   },
   "outputs": [],
   "source": [
    "# Salvar o modelo treinado\n",
    "\n",
    "torch.save(modelo.state_dict(), \"modelo_labglassware.pth\")\n",
    "print(\"‚úÖ Modelo salvo como modelo_labglassware.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
